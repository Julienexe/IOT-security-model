{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10793343,"sourceType":"datasetVersion","datasetId":6698197}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset\nfile_path = \"/kaggle/input/rt-iot2022/RT_IOT2022.csv\"  # Update with correct path\ndf = pd.read_csv(file_path)\n\n# Check class distribution\nprint(df['Attack_type'].value_counts(normalize=True) * 100)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport networkx as nx\nfrom torch_geometric.data import Data\nfrom sklearn.preprocessing import LabelEncoder\n\n# Load the dataset\nfile_path = \"/kaggle/input/rt-iot2022/RT_IOT2022.csv\"  # Update path if needed\ndf = pd.read_csv(file_path)\n\n# Step 1: Create a mapping of ports to unique node indices\nunique_ports = pd.concat([df[\"id.orig_p\"], df[\"id.resp_p\"]]).unique()\nport_to_index = {port: idx for idx, port in enumerate(unique_ports)}\n\n# Step 2: Create edge list (source -> destination) using port indices\nedge_index = torch.tensor([\n    [port_to_index[src], port_to_index[dst]] \n    for src, dst in zip(df[\"id.orig_p\"], df[\"id.resp_p\"])\n], dtype=torch.long).t()  # Transpose to match PyTorch Geometric format\n\n# Step 3: Extract edge features (flow duration, packet counts)\nedge_features = torch.tensor(df[[\"flow_duration\", \"fwd_pkts_tot\", \"bwd_pkts_tot\"]].values, dtype=torch.float)\n\n# Step 4: Create node features (aggregate statistics per node)\nnode_features_df = df.groupby(\"id.orig_p\")[[\"fwd_pkts_tot\", \"bwd_pkts_tot\", \"flow_duration\"]].mean().reset_index()\nnode_features = torch.tensor(node_features_df[[\"fwd_pkts_tot\", \"bwd_pkts_tot\", \"flow_duration\"]].values, dtype=torch.float)\n\n# Step 5: Encode labels (Anomaly Detection: Attack_type)\nlabel_encoder = LabelEncoder()\nlabels = torch.tensor(label_encoder.fit_transform(df[\"Attack_type\"]), dtype=torch.long)\n\n# Create PyTorch Geometric Data object\ngraph_data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features, y=labels)\n\n# Print graph data summary\nprint(graph_data)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GATConv\nfrom torch_geometric.data import DataLoader\n\n# Define the Graph Attention Network (GAT) Model\nclass GATAnomalyDetector(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, heads=2, dropout=0.3):\n        super(GATAnomalyDetector, self).__init__()\n        \n        # First GAT Layer\n        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n        \n        # Second GAT Layer\n        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout)\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index)\n        x = F.elu(x)  # Activation Function\n        x = self.conv2(x, edge_index)\n        return F.log_softmax(x, dim=1)  # Output probabilities\n\n# Define Model Parameters\nin_channels = graph_data.x.shape[1]  # Number of node features\nhidden_channels = 16\nout_channels = len(torch.unique(graph_data.y))  # Number of classes (anomalies)\n\n# Initialize Model\ngat_model = GATAnomalyDetector(in_channels, hidden_channels, out_channels)\nprint(gat_model)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GATConv\nfrom torch_geometric.data import Data\nfrom torch.optim import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score, classification_report\nfrom imblearn.over_sampling import SMOTE\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/rt-iot2022/RT_IOT2022.csv\")\n\n# Encode categorical features\ncategorical_columns = df.select_dtypes(include=['object']).columns\nlabel_encoders = {}\nfor col in categorical_columns:\n    le = LabelEncoder()\n    df[col] = le.fit_transform(df[col])\n    label_encoders[col] = le\n\n# Separate features and target variable\nX = df.drop(columns=['Attack_type'])\ny = df['Attack_type']\n\n# Normalize numerical features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Handle class imbalance using SMOTE\nsmote = SMOTE(random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n\n# Split dataset\nX_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n\n# Convert to PyTorch tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float)\ny_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\ny_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n\n# Convert to Graph Data\nedge_index = torch.randint(0, X_train_tensor.shape[0], (2, X_train_tensor.shape[0] * 2))\ngraph_data = Data(x=X_train_tensor, edge_index=edge_index, y=y_train_tensor)\n\ndef preprocess_graph_data(graph_data):\n    \"\"\"Ensure valid edge indices.\"\"\"\n    num_nodes = graph_data.x.size(0)\n    valid_edges_mask = (graph_data.edge_index[0] < num_nodes) & (graph_data.edge_index[1] < num_nodes)\n    graph_data.edge_index = graph_data.edge_index[:, valid_edges_mask]\n    return graph_data\n\ngraph_data = preprocess_graph_data(graph_data)\n\n# Define GAT Model\nclass GATAnomalyDetector(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, heads=2, dropout=0.3):\n        super(GATAnomalyDetector, self).__init__()\n        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout)\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index)\n        x = F.elu(x)\n        x = self.conv2(x, edge_index)\n        return F.log_softmax(x, dim=1)\n\n# Initialize Model\nin_channels = X_train_tensor.shape[1]\nhidden_channels = 16\nout_channels = len(torch.unique(y_train_tensor))\ngat_model = GATAnomalyDetector(in_channels, hidden_channels, out_channels)\n\n# Optimizer and Loss\noptimizer = Adam(gat_model.parameters(), lr=0.005, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\n# Training Function\ndef train():\n    gat_model.train()\n    optimizer.zero_grad()\n    out = gat_model(graph_data.x, graph_data.edge_index)\n    loss = loss_fn(out, graph_data.y)\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n\n# Evaluate Model\ndef evaluate_model(model, data, show_plots=True):\n    model.eval()\n    with torch.no_grad():\n        out = model(data.x, data.edge_index)\n        pred = out.argmax(dim=1)\n        y_true = data.y.cpu().numpy()\n        y_pred = pred.cpu().numpy()\n\n        # Compute metrics\n        accuracy = accuracy_score(y_true, y_pred)\n        precision = precision_score(y_true, y_pred, average='weighted', zero_division=1)\n        recall = recall_score(y_true, y_pred, average='weighted', zero_division=1)\n        f1 = f1_score(y_true, y_pred, average='weighted')\n\n        print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n        print(f\"\\nAccuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n\n        # Plot Confusion Matrix\n        if show_plots:\n            cm = confusion_matrix(y_true, y_pred)\n            plt.figure(figsize=(8, 6))\n            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_true), yticklabels=np.unique(y_true))\n            plt.xlabel(\"Predicted Label\")\n            plt.ylabel(\"True Label\")\n            plt.title(\"Confusion Matrix\")\n            plt.show()\n\n        return {\n            'accuracy': accuracy,\n            'precision': precision,\n            'recall': recall,\n            'f1_score': f1,\n            'predictions': y_pred,\n            'true_labels': y_true\n        }\n\n# Train Model\nnum_epochs = 2000\nfor epoch in range(num_epochs):\n    loss = train()\n    if (epoch + 1) % 5 == 0:\n        eval_metrics = evaluate_model(gat_model, graph_data, show_plots=False)\n        print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Accuracy={eval_metrics['accuracy']:.4f}, F1-Score={eval_metrics['f1_score']:.4f}\")\n\n# Final Evaluation with Confusion Matrix\nfinal_metrics = evaluate_model(gat_model, graph_data, show_plots=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.0.0+cpu.html","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(gat_model.state_dict(), \"gat_teacher.pth\")\nprint(\"Teacher model saved successfully! âœ…\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GATConv\nfrom torch.optim import Adam\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom torch_geometric.data import Data\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom imblearn.over_sampling import SMOTE\n\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/rt-iot2022/RT_IOT2022.csv\")\n\n# Encode categorical features\ncategorical_columns = df.select_dtypes(include=['object']).columns\nlabel_encoders = {}\nfor col in categorical_columns:\n    le = LabelEncoder()\n    df[col] = le.fit_transform(df[col])\n    label_encoders[col] = le\n\n# Features & Labels\nX = df.drop(columns=['Attack_type'])\ny = df['Attack_type']\n\n# Standardize features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Handle class imbalance using SMOTE\nsmote = SMOTE(random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n\n# Split dataset\nX_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n\n# Convert to PyTorch tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float)\ny_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\ny_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n\n# Create Graph Data\nedge_index = torch.randint(0, X_train_tensor.shape[0], (2, X_train_tensor.shape[0] * 2))\ngraph_data = Data(x=X_train_tensor, edge_index=edge_index, y=y_train_tensor)\n\n# Define Teacher Model\nclass GATTeacher(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, heads=2, dropout=0.3):\n        super(GATTeacher, self).__init__()\n        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout)\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index)\n        x = F.elu(x)\n        x = self.conv2(x, edge_index)\n        return F.log_softmax(x, dim=1)\n\n# Initialize Teacher Model\nin_channels = X_train_tensor.shape[1]\nhidden_channels = 16\nout_channels = len(torch.unique(y_train_tensor))\ngat_teacher = GATTeacher(in_channels, hidden_channels, out_channels)\n\n# Optimizer & Loss\noptimizer = Adam(gat_teacher.parameters(), lr=0.005, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\n# Train Teacher Model\ndef train_teacher():\n    gat_teacher.train()\n    optimizer.zero_grad()\n    out = gat_teacher(graph_data.x, graph_data.edge_index)\n    loss = loss_fn(out, graph_data.y)\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n\n# Training loop\nnum_epochs_teacher = 500\nfor epoch in range(num_epochs_teacher):\n    loss = train_teacher()\n    if (epoch + 1) % 5 == 0:\n        print(f\"Teacher Epoch {epoch+1}: Loss={loss:.4f}\")\n\n# Save Teacher Model\ntorch.save(gat_teacher.state_dict(), \"gat_teacher.pth\")\nprint(\"âœ… Teacher Model Training Complete & Saved\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Teacher Model\ngat_teacher = GATTeacher(in_channels, hidden_channels, out_channels)\ngat_teacher.load_state_dict(torch.load(\"gat_teacher.pth\"))\ngat_teacher.eval()\n\n# Define Student Model\nclass GATStudent(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, heads=1, dropout=0.3):\n        super(GATStudent, self).__init__()\n        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout)\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index)\n        x = F.elu(x)\n        x = self.conv2(x, edge_index)\n        return F.log_softmax(x, dim=1)\n\n# Initialize Student Model\nhidden_channels_student = 8  # Smaller hidden layer\ngat_student = GATStudent(in_channels, hidden_channels_student, out_channels)\n\n# Optimizer for Student\nstudent_optimizer = Adam(gat_student.parameters(), lr=0.005, weight_decay=5e-4)\n\n# Distillation Loss Function\ndef distillation_loss(student_logits, teacher_logits, labels, temperature=3, alpha=0.7):\n    soft_targets = F.softmax(teacher_logits / temperature, dim=1)\n    student_probs = F.log_softmax(student_logits / temperature, dim=1)\n    kl_div_loss = F.kl_div(student_probs, soft_targets, reduction=\"batchmean\") * (temperature ** 2)\n    ce_loss = F.cross_entropy(student_logits, labels)\n    return alpha * kl_div_loss + (1 - alpha) * ce_loss\n\n# Train Student Model\ndef train_student():\n    gat_student.train()\n    student_optimizer.zero_grad()\n\n    with torch.no_grad():\n        teacher_outputs = gat_teacher(graph_data.x, graph_data.edge_index)\n\n    student_outputs = gat_student(graph_data.x, graph_data.edge_index)\n\n    loss = distillation_loss(student_outputs, teacher_outputs, graph_data.y)\n\n    loss.backward()\n    student_optimizer.step()\n    \n    return loss.item()\n\n# Training loop\nnum_epochs_student = 500\nfor epoch in range(num_epochs_student):\n    loss = train_student()\n    if (epoch + 1) % 5 == 0:\n        print(f\"Student Epoch {epoch+1}: Loss={loss:.4f}\")\n\n# Save Student Model\ntorch.save(gat_student.state_dict(), \"gat_student.pth\")\nprint(\"âœ… Student Model Training Complete & Saved\")\n\n\n# -------------------------------\n# ðŸ“Œ Student Model Evaluation\n# -------------------------------\n\n# Filter edge_index to ensure all indices are within valid range\nvalid_mask = (edge_index[0] < X_test.shape[0]) & (edge_index[1] < X_test.shape[0])\nedge_index = edge_index[:, valid_mask]\n\n# Verify the fix\nmax_index_after = edge_index.max().item()\nprint(f\"Max index in edge_index after filtering: {max_index_after}, Node count: {X_test.shape[0]}\")\n\ndef evaluate_student():\n    gat_student.eval()\n    with torch.no_grad():\n        student_outputs = gat_student(X_test_tensor, edge_index)\n        student_predictions = student_outputs.argmax(dim=1).cpu().numpy()\n\n    y_test_np = y_test_tensor.cpu().numpy()\n\n    accuracy = accuracy_score(y_test_np, student_predictions)\n    precision = precision_score(y_test_np, student_predictions, average='weighted', zero_division=1)\n    recall = recall_score(y_test_np, student_predictions, average='weighted', zero_division=1)\n    f1 = f1_score(y_test_np, student_predictions, average='weighted', zero_division=1)\n\n    print(\"\\nðŸŽ¯ **Student Model Evaluation Results**:\")\n    print(f\"âœ… Accuracy: {accuracy:.4f}\")\n    print(f\"âœ… Precision: {precision:.4f}\")\n    print(f\"âœ… Recall: {recall:.4f}\")\n    print(f\"âœ… F1 Score: {f1:.4f}\")\n\n# Run evaluation\nevaluate_student()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef evaluate_student():\n    gat_student.eval()\n    with torch.no_grad():\n        student_outputs = gat_student(X_test_tensor, edge_index)\n        student_predictions = student_outputs.argmax(dim=1).cpu().numpy()\n\n    y_test_np = y_test_tensor.cpu().numpy()\n\n    accuracy = accuracy_score(y_test_np, student_predictions)\n    precision = precision_score(y_test_np, student_predictions, average='weighted', zero_division=1)\n    recall = recall_score(y_test_np, student_predictions, average='weighted', zero_division=1)\n    f1 = f1_score(y_test_np, student_predictions, average='weighted', zero_division=1)\n\n    print(\"\\nðŸŽ¯ **Student Model Evaluation Results**:\")\n    print(f\"âœ… Accuracy: {accuracy:.4f}\")\n    print(f\"âœ… Precision: {precision:.4f}\")\n    print(f\"âœ… Recall: {recall:.4f}\")\n    print(f\"âœ… F1 Score: {f1:.4f}\")\n\n    # Create confusion matrix\n    cm = confusion_matrix(y_test_np, student_predictions)\n\n    # Plot confusion matrix\n    plt.figure(figsize=(6, 4))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n\n# Run evaluation\nevaluate_student()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load the trained student model\nstudent_model = tf.keras.models.load_model(\"student_model_fixed.h5\")\n\n# Make predictions\nstudent_preds = student_model.predict(X_test)\nstudent_preds_binary = (student_preds > 0.5).astype(int)\n\n# Compute evaluation metrics\naccuracy_student = accuracy_score(y_test, student_preds_binary)\nroc_auc_student = roc_auc_score(y_test, student_preds_binary)\nconf_matrix = confusion_matrix(y_test, student_preds_binary)\n\n# Print results\nprint(\"\\nðŸ”¹ Student Model Accuracy:\", accuracy_student)\nprint(\"\\nðŸ”¹ Student Model ROC-AUC Score:\", roc_auc_student)\nprint(\"\\nðŸ”¹ Classification Report (Student Model):\\n\", classification_report(y_test, student_preds_binary))\n\n# Plot Confusion Matrix\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Normal\", \"Attack\"], yticklabels=[\"Normal\", \"Attack\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix - Student Model\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}