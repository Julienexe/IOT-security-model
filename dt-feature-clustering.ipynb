{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomUnderSampler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Input, Dense\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from scipy.stats import mode\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"C://Users//JP//Desktop//csc//Year 2//sem 2//Machine Learning//iot//Scripts//RT_IOT2022.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns if present\n",
    "df = df.drop(columns=['Unnamed: 0']) if 'Unnamed: 0' in df.columns else df\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = ['proto', 'service', 'Attack_type']  # Update if needed\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Extract Features and Labels\n",
    "X = df.drop(columns=['Attack_type']).values  # Features\n",
    "y = df['Attack_type'].values  # Target\n",
    "\n",
    "# Undersample the majority class\n",
    "undersample = RandomUnderSampler(sampling_strategy={max(set(y), key=list(y).count): 7000}, random_state=42)\n",
    "X_under, y_under = undersample.fit_resample(X, y)\n",
    "\n",
    "# Oversample minority classes\n",
    "oversample = RandomOverSampler(sampling_strategy={cls: 5000 for cls in np.unique(y) if list(y).count(cls) < 5000}, random_state=42)\n",
    "X_resampled, y_resampled = oversample.fit_resample(X_under, y_under)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Autoencoder\n",
    "input_dim = X_scaled.shape[1]\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(64, activation='relu')(input_layer)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "encoded = Dense(16, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(32, activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(decoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train Autoencoder\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=256, shuffle=True)\n",
    "\n",
    "# Extract Encoded Features\n",
    "encoder = Model(input_layer, encoded)\n",
    "X_encoded = encoder.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train K-Means on Encoded Features\n",
    "optimal_k = 5  # Replace with best K found from Elbow Method\n",
    "kmeans = KMeans(n_clusters=optimal_k, init='k-means++', random_state=42, n_init=50)\n",
    "kmeans.fit(X_encoded)\n",
    "\n",
    "df['Cluster'] = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score (K-Means Student Model): 0.3605\n",
      "Accuracy: 0.2277\n",
      "Precision: 0.1578\n",
      "Recall: 0.2277\n",
      "F1 Score: 0.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JP\\Desktop\\csc\\Year 2\\sem 2\\Machine Learning\\iot\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Function to Map Clusters to True Labels\n",
    "def assign_cluster_labels(true_labels, cluster_labels):\n",
    "    labels = np.zeros_like(cluster_labels)\n",
    "    for cluster in np.unique(cluster_labels):\n",
    "        mask = cluster_labels == cluster\n",
    "        true_label = mode(true_labels[mask])[0][0]  # Extract most frequent class\n",
    "        labels[mask] = true_label\n",
    "    return labels\n",
    "\n",
    "# Evaluate Performance\n",
    "sil_score = silhouette_score(X_encoded, kmeans.labels_)\n",
    "ari = adjusted_rand_score(y_resampled, kmeans.labels_)\n",
    "nmi = normalized_mutual_info_score(y_resampled, kmeans.labels_)\n",
    "\n",
    "true_labels = y_resampled\n",
    "predicted_labels = assign_cluster_labels(true_labels, df['Cluster'])\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Silhouette Score: {sil_score:.4f}\")\n",
    "print(f\"Adjusted Rand Index (ARI): {ari:.4f}\")\n",
    "print(f\"Normalized Mutual Information (NMI): {nmi:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Clusters using PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_encoded)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=df['Cluster'], palette='viridis')\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.title(\"K-Means Clustering After Knowledge Distillation\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iotkernel",
   "language": "python",
   "name": "iotkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
