{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7364862,"sourceType":"datasetVersion","datasetId":4278448}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import mixed_precision\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nmixed_precision.set_global_policy('float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T13:25:19.533720Z","iopub.execute_input":"2025-02-26T13:25:19.534040Z","iopub.status.idle":"2025-02-26T13:25:19.538867Z","shell.execute_reply.started":"2025-02-26T13:25:19.534014Z","shell.execute_reply":"2025-02-26T13:25:19.537972Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\n\n# Check if GPU is available and configure it\nphysical_devices = tf.config.list_physical_devices('GPU')\nif physical_devices:\n    print(\"GPU is available:\", physical_devices)\n    # Configure GPU for optimal performance\n    try:\n        for gpu in physical_devices:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(\"Memory growth enabled\")\n    except:\n        print(\"Memory growth already enabled\")\n    # Set mixed precision policy for faster GPU computation\n    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n    tf.keras.mixed_precision.set_global_policy(policy)\n    print(\"Mixed precision policy set to:\", policy.name)\nelse:\n    print(\"No GPU found\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T13:22:21.253256Z","iopub.execute_input":"2025-02-26T13:22:21.253704Z","iopub.status.idle":"2025-02-26T13:22:21.879985Z","shell.execute_reply.started":"2025-02-26T13:22:21.253682Z","shell.execute_reply":"2025-02-26T13:22:21.878966Z"}},"outputs":[{"name":"stdout","text":"GPU is available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\nMemory growth enabled\nMixed precision policy set to: mixed_float16\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\n\n# Load and preprocess the dataset\ndf = pd.read_csv(\"/kaggle/input/rt-iot2022real-time-internet-of-things/RT_IOT2022.csv\")\ndf = df.drop(columns=['Unnamed: 0']) if 'Unnamed: 0' in df.columns else df\n\n# Encode categorical variables\nlabel_encoders = {}\ncategorical_columns = ['proto', 'service', 'Attack_type']\nfor col in categorical_columns:\n    le = LabelEncoder()\n    df[col] = le.fit_transform(df[col])\n    label_encoders[col] = le\n\n# Prepare features and target\nX = df.drop(columns=['Attack_type']).values\ny = df['Attack_type'].values\nnum_classes = len(np.unique(y))\n\n# Normalize features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Convert to proper shape for CNN and convert labels to one-hot\nX_train_reshaped = X_train.reshape(-1, X_train.shape[1], 1)\nX_test_reshaped = X_test.reshape(-1, X_test.shape[1], 1)\ny_train_categorical = tf.keras.utils.to_categorical(y_train, num_classes)\ny_test_categorical = tf.keras.utils.to_categorical(y_test, num_classes)\n\n# Calculate class weights instead of using SMOTE (faster)\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = dict(zip(np.unique(y_train), class_weights))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T13:22:21.882201Z","iopub.execute_input":"2025-02-26T13:22:21.882730Z","iopub.status.idle":"2025-02-26T13:22:24.099551Z","shell.execute_reply.started":"2025-02-26T13:22:21.882696Z","shell.execute_reply":"2025-02-26T13:22:24.098634Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\n\n# Create TensorFlow datasets with prefetching for better GPU utilization\nBATCH_SIZE = 512  # Larger batch size for GPU\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train_reshaped, y_train_categorical))\ntrain_ds = train_ds.cache().shuffle(10000).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n\nval_ds = tf.data.Dataset.from_tensor_slices((X_test_reshaped, y_test_categorical))\nval_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n\n# TEACHER MODEL: More complex architecture\nteacher_model = Sequential([\n    Conv1D(64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train.shape[1], 1)),\n    BatchNormalization(momentum=0.9),\n    MaxPooling1D(pool_size=2),\n    Dropout(0.3),\n    \n    Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n    BatchNormalization(momentum=0.9),\n    MaxPooling1D(pool_size=2),\n    Dropout(0.4),\n    \n    Conv1D(256, kernel_size=3, activation='relu', padding='same'),\n    BatchNormalization(momentum=0.9),\n    MaxPooling1D(pool_size=2),\n    Dropout(0.4),\n    \n    Flatten(),\n    Dense(128, activation='relu'),\n    BatchNormalization(momentum=0.9),\n    Dropout(0.5),\n    Dense(num_classes, activation='softmax')\n])\n\n# Compile with proper dtype for mixed precision\nteacher_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Train teacher with optimized callbacks\nteacher_callbacks = [\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n]\n\nprint(\"Training teacher model...\")\nteacher_history = teacher_model.fit(\n    train_ds,\n    epochs=15,  # Reduced epochs since we're using larger batches\n    validation_data=val_ds,\n    callbacks=teacher_callbacks,\n    verbose=1\n)\n\n# Generate soft targets with teacher model\nprint(\"Generating soft targets from teacher model...\")\ntemperature = 4.0\nteacher_preds = teacher_model.predict(X_train_reshaped, batch_size=BATCH_SIZE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T13:22:24.100641Z","iopub.execute_input":"2025-02-26T13:22:24.100915Z","iopub.status.idle":"2025-02-26T13:23:01.395359Z","shell.execute_reply.started":"2025-02-26T13:22:24.100895Z","shell.execute_reply":"2025-02-26T13:23:01.394526Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Training teacher model...\nEpoch 1/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 45ms/step - accuracy: 0.6735 - loss: 1.3082 - val_accuracy: 0.9750 - val_loss: 0.0730 - learning_rate: 0.0010\nEpoch 2/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9710 - loss: 0.0979 - val_accuracy: 0.9849 - val_loss: 0.0460 - learning_rate: 0.0010\nEpoch 3/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9806 - loss: 0.0648 - val_accuracy: 0.9887 - val_loss: 0.0344 - learning_rate: 0.0010\nEpoch 4/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.0462 - val_accuracy: 0.9915 - val_loss: 0.0286 - learning_rate: 0.0010\nEpoch 5/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9876 - loss: 0.0408 - val_accuracy: 0.9922 - val_loss: 0.0243 - learning_rate: 0.0010\nEpoch 6/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9890 - loss: 0.0358 - val_accuracy: 0.9932 - val_loss: 0.0215 - learning_rate: 0.0010\nEpoch 7/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9900 - loss: 0.0299 - val_accuracy: 0.9927 - val_loss: 0.0242 - learning_rate: 0.0010\nEpoch 8/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9903 - loss: 0.0308 - val_accuracy: 0.9944 - val_loss: 0.0187 - learning_rate: 0.0010\nEpoch 9/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9909 - loss: 0.0277 - val_accuracy: 0.9948 - val_loss: 0.0192 - learning_rate: 0.0010\nEpoch 10/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9918 - loss: 0.0256 - val_accuracy: 0.9945 - val_loss: 0.0183 - learning_rate: 0.0010\nEpoch 11/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9922 - loss: 0.0240 - val_accuracy: 0.9946 - val_loss: 0.0175 - learning_rate: 0.0010\nEpoch 12/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 0.0215 - val_accuracy: 0.9946 - val_loss: 0.0172 - learning_rate: 0.0010\nEpoch 13/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9930 - loss: 0.0216 - val_accuracy: 0.9950 - val_loss: 0.0175 - learning_rate: 0.0010\nEpoch 14/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9931 - loss: 0.0216 - val_accuracy: 0.9950 - val_loss: 0.0163 - learning_rate: 0.0010\nEpoch 15/15\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9934 - loss: 0.0215 - val_accuracy: 0.9950 - val_loss: 0.0159 - learning_rate: 0.0010\nGenerating soft targets from teacher model...\n\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Create custom distillation loss with built-in temperature handling\nclass DistillationModel(tf.keras.Model):\n    def __init__(self, student_model, teacher_predictions, temperature=4.0, alpha=0.1):\n        super(DistillationModel, self).__init__()\n        self.student_model = student_model\n        self.teacher_predictions = teacher_predictions\n        self.temperature = temperature\n        self.alpha = alpha\n        \n    def compile(self, optimizer, metrics):\n        super(DistillationModel, self).compile(optimizer=optimizer, metrics=metrics)\n        self.loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n        \n    def train_step(self, data):\n        x, y_true = data\n        \n        with tf.GradientTape() as tape:\n            y_pred = self.student_model(x, training=True)\n            \n            # Hard loss - standard cross-entropy with true labels\n            hard_loss = self.loss_fn(y_true, y_pred)\n            \n            # Soft targets - using pre-computed teacher predictions\n            # Get correct indices for the batch\n            batch_indices = tf.range(tf.shape(x)[0])\n            soft_targets = tf.gather(self.teacher_predictions, batch_indices)\n            \n            # Apply temperature scaling\n            soft_targets = tf.nn.softmax(soft_targets / self.temperature)\n            soft_pred = tf.nn.softmax(y_pred / self.temperature)\n            \n            # Soft loss - KL divergence\n            soft_loss = tf.keras.losses.kullback_leibler_divergence(soft_targets, soft_pred)\n            soft_loss = soft_loss * (self.temperature ** 2)\n            \n            # Combine losses\n            total_loss = (1 - self.alpha) * hard_loss + self.alpha * soft_loss\n        \n        # Compute gradients and update weights\n        gradients = tape.gradient(total_loss, self.student_model.trainable_variables)\n        self.optimizer.apply_gradients(zip(gradients, self.student_model.trainable_variables))\n        \n        # Update metrics\n        self.compiled_metrics.update_state(y_true, y_pred)\n        results = {m.name: m.result() for m in self.metrics}\n        results.update({\"loss\": total_loss})\n        \n        return results\n    \n    def call(self, inputs):\n        return self.student_model(inputs)\n\n# Create small, fast student model\nstudent_model = Sequential([\n    Conv1D(16, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n    MaxPooling1D(pool_size=2),\n    Dropout(0.3),\n    \n    Conv1D(32, kernel_size=3, activation='relu'),\n    MaxPooling1D(pool_size=2),\n    Dropout(0.4),\n    \n    Flatten(),\n    Dense(32, activation='relu'),\n    Dropout(0.4),\n    Dense(num_classes, activation='softmax')\n])\n\n# Wrap student model in the distillation model\ndistillation_model = DistillationModel(\n    student_model=student_model,\n    teacher_predictions=teacher_preds,\n    temperature=temperature,\n    alpha=0.3  # Weight for soft targets vs hard targets\n)\n\n# Compile distillation model\ndistillation_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    metrics=['accuracy']\n)\n\n# Train student model with distillation\nprint(\"Training student model with knowledge distillation...\")\nstudent_callbacks = [\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n]\n\nstudent_history = distillation_model.fit(\n    train_ds,\n    epochs=15,\n    validation_data=val_ds,\n    callbacks=student_callbacks,\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T13:28:01.940262Z","iopub.execute_input":"2025-02-26T13:28:01.940598Z","iopub.status.idle":"2025-02-26T13:28:07.666578Z","shell.execute_reply.started":"2025-02-26T13:28:01.940559Z","shell.execute_reply":"2025-02-26T13:28:07.665447Z"}},"outputs":[{"name":"stdout","text":"Training student model with knowledge distillation...\nEpoch 1/15\n\u001b[1m177/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7534 - loss: 0.4173","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-c4ed90d78c96>\u001b[0m in \u001b[0;36m<cell line: 90>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m ]\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m student_history = distillation_model.fit(\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5982\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5983\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:AddV2] name: "],"ename":"InvalidArgumentError","evalue":"{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:AddV2] name: ","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"\n\n# Evaluate both models\nprint(\"Evaluating teacher model...\")\nteacher_eval = teacher_model.evaluate(val_ds, verbose=1)\nprint(f\"Teacher model - Loss: {teacher_eval[0]:.4f}, Accuracy: {teacher_eval[1]:.4f}\")\n\nprint(\"Evaluating student model...\")\nstudent_eval = distillation_model.evaluate(val_ds, verbose=1)\nprint(f\"Student model - Loss: {student_eval[0]:.4f}, Accuracy: {student_eval[1]:.4f}\")\n\n# Make predictions with student model\nprint(\"Generating predictions with student model...\")\ny_pred = distillation_model.predict(X_test_reshaped, batch_size=BATCH_SIZE)\ny_pred_labels = np.argmax(y_pred, axis=1)\ny_test_labels = np.argmax(y_test_categorical, axis=1)\n\n# Calculate metrics\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nprint(\"\\nClassification Report (Student Model):\")\nprint(classification_report(y_test_labels, y_pred_labels))\n\n# Calculate precision, recall, and F1 score\naccuracy = accuracy_score(y_test_labels, y_pred_labels)\nprint(f\"Accuracy: {accuracy:.4f}\")\n\n# Compare model sizes\nteacher_params = teacher_model.count_params()\nstudent_params = student_model.count_params()\nreduction_percentage = (1 - student_params / teacher_params) * 100\n\nprint(f\"\\nModel Size Comparison:\")\nprint(f\"Teacher model parameters: {teacher_params:,}\")\nprint(f\"Student model parameters: {student_params:,}\")\nprint(f\"Size reduction: {reduction_percentage:.2f}%\")\nprint(f\"Inference speed improvement should be approximately {1/(1-reduction_percentage/100):.2f}x faster\")\n\n# Save the student model\nstudent_model.save('distilled_iot_model.h5')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-26T13:23:01.902556Z","iopub.status.idle":"2025-02-26T13:23:01.902787Z","shell.execute_reply":"2025-02-26T13:23:01.902690Z"}},"outputs":[],"execution_count":null}]}